{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7116be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# Viktig: bruk modul-import for low-level XGBoost API\n",
    "import xgboost as xgb  # nå peker 'xgb' på modulen, ikke en modell-klasse\n",
    "\n",
    "# (Valgfritt) dersom du senere vil teste sklearn-wrapperen:\n",
    "# from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69fe71a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last inn data\n",
    "purchase_orders = pd.read_csv(\"data/kernel/purchase_orders.csv\", parse_dates=[\"delivery_date\", \"created_date_time\", \"modified_date_time\"])\n",
    "receivals = pd.read_csv(\"data/kernel/receivals.csv\", parse_dates=[\"date_arrival\"])\n",
    "raw_material = pd.read_csv(\"data/extended/materials.csv\")\n",
    "transportation = pd.read_csv(\"data/extended/transportation.csv\")\n",
    "\n",
    "\n",
    "purchase_orders_clean = purchase_orders[purchase_orders['quantity'] > 0]\n",
    "purchase_orders_clean = purchase_orders_clean[purchase_orders_clean['status'] != 'Deleted']\n",
    "receivals_clean = receivals[receivals['net_weight'] > 0]\n",
    "\n",
    "purchase_base = purchase_orders_clean[[\"purchase_order_id\", \n",
    "                                       \"quantity\",\n",
    "                                       \"created_date_time\",\n",
    "                                       \"purchase_order_item_no\",\n",
    "                                       ]]\n",
    "\n",
    "receivals_base = receivals_clean[[\"rm_id\",\n",
    "                                 \"purchase_order_id\",\n",
    "                                 \"purchase_order_item_no\",\n",
    "                                 \"product_id\",\n",
    "                                 \"date_arrival\",\n",
    "                                 \"net_weight\"\n",
    "                                 ]]\n",
    "\n",
    "rec_ord_merged = receivals_base.merge(\n",
    "    purchase_base,\n",
    "    on = [\"purchase_order_id\", \"purchase_order_item_no\"],\n",
    "    how = \"inner\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccec5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rec_ord_merged.copy()\n",
    "\n",
    "for c in [\"date_arrival\", \"created_date_time\"]:\n",
    "    df[c] = pd.to_datetime(df[c], errors=\"coerce\", utc=True).dt.tz_localize(None)\n",
    "    \n",
    "df[\"delivery_year\"]    = df[\"date_arrival\"].dt.year\n",
    "df[\"delivery_month\"]   = df[\"date_arrival\"].dt.month\n",
    "df[\"delivery_weekday\"] = df[\"date_arrival\"].dt.weekday\n",
    "df[\"lead_time_days\"] = (df[\"date_arrival\"] - df[\"created_date_time\"]).dt.days\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48a41be1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train/Test shapes: (116169, 7) (5993, 7)\n",
      "Head features:\n",
      "    rm_id  product_id   quantity  delivery_year  delivery_month  \\\n",
      "0  365.0  91900143.0  1975000.0           2004               6   \n",
      "1  365.0  91900143.0  1975000.0           2004               6   \n",
      "2  365.0  91900143.0  1500000.0           2004               6   \n",
      "3  365.0  91900143.0  1500000.0           2004               6   \n",
      "4  379.0  91900296.0   125000.0           2004               6   \n",
      "\n",
      "   delivery_weekday  lead_time_days  \n",
      "0                 1             153  \n",
      "1                 1             153  \n",
      "2                 1             158  \n",
      "3                 1             158  \n",
      "4                 1             -10  \n"
     ]
    }
   ],
   "source": [
    "# Feature engineering uten lekkasje (fjerner target leakage: 'net_weight' og avledet 'delivery_ratio')\n",
    "# Tidligere features inkluderte net_weight (målvariabelen) og delivery_ratio (avhenger av net_weight) -> ga overfitting og for høye prediksjoner.\n",
    "\n",
    "# Behold kun variabler som er kjent ved bestillingstidspunkt / før leveransens faktiske vekt er kjent.\n",
    "# (Hvis 'lead_time_days' brukes i sanntid må den være basert på informasjon tilgjengelig ved prediksjon; beholder den her.)\n",
    "\n",
    "weight_diff = df[\"net_weight\"] - df[\"quantity\"]  # kun for analyse (ikke feature)\n",
    "\n",
    "# Ny, ren featureliste\n",
    "features = [\n",
    "    'rm_id',\n",
    "    'product_id',\n",
    "    'quantity',\n",
    "    'delivery_year',\n",
    "    'delivery_month',\n",
    "    'delivery_weekday',\n",
    "    'lead_time_days'\n",
    "]\n",
    "\n",
    "X = df[features].copy()\n",
    "Y = df[\"net_weight\"].values  # target\n",
    "\n",
    "train_mask = df[\"date_arrival\"] < pd.Timestamp(\"2024-01-01\")\n",
    "X_train, Y_train = X[train_mask], Y[train_mask]\n",
    "X_test,  Y_test  = X[~train_mask], Y[~train_mask]\n",
    "\n",
    "test = df.loc[~train_mask].copy()\n",
    "\n",
    "print(\"Train/Test shapes:\", X_train.shape, X_test.shape)\n",
    "print(\"Head features:\\n\", X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5efebf0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] xgboost version: 3.0.1\n",
      "[Diag] train: shape=(116169, 7), nan_filled=0, dtypes_ok=True\n",
      "[Diag] test: shape=(5993, 7), nan_filled=0, dtypes_ok=True\n",
      "Iter    0 | val_q20_loss=2592.805707 | train_q20_loss=2219.157409 | best=2592.805707 (iter 0)\n",
      "Iter   99 | val_q20_loss=2592.805707 | train_q20_loss=2219.157409 | best=2592.805707 (iter 0)\n",
      "Iter   99 | val_q20_loss=2592.805707 | train_q20_loss=2219.157409 | best=2592.805707 (iter 0)\n",
      "[EarlyStopping] Ingen forbedring siste 120 runder. Stopper ved iter 120.\n",
      "Best iteration: 0  (val_q20_loss=2592.805707)\n",
      "Revidert modell – kvantil-tap q=0.2: 2592.072204\n",
      "Baseline (konstant) q-loss: 2596.3913899549475\n",
      "Baseline (0.85*quantity) q-loss: 267352.41462205903\n",
      "RMSE (sekundær): 13728.278004728034\n",
      "Andel prediksjoner <= faktisk vekt: 0.789\n",
      "Siste 5 val_q20_loss: [2592.8057066577676, 2592.8057066577676, 2592.8057066577676, 2592.8057066577676, 2592.8057066577676]\n",
      "[EarlyStopping] Ingen forbedring siste 120 runder. Stopper ved iter 120.\n",
      "Best iteration: 0  (val_q20_loss=2592.805707)\n",
      "Revidert modell – kvantil-tap q=0.2: 2592.072204\n",
      "Baseline (konstant) q-loss: 2596.3913899549475\n",
      "Baseline (0.85*quantity) q-loss: 267352.41462205903\n",
      "RMSE (sekundær): 13728.278004728034\n",
      "Andel prediksjoner <= faktisk vekt: 0.789\n",
      "Siste 5 val_q20_loss: [2592.8057066577676, 2592.8057066577676, 2592.8057066577676, 2592.8057066577676, 2592.8057066577676]\n"
     ]
    }
   ],
   "source": [
    "# Revidert XGBoost kvantilmodell (q=0.2) – manuell early stopping (feval ikke støttet i miljøet)\n",
    "q = 0.2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import traceback, math, copy\n",
    "\n",
    "print(\"[Info] xgboost version:\", xgb.__version__)\n",
    "\n",
    "# --- Robust pre-flight diagnostikk og rensing ---\n",
    "\n",
    "def _clean_features(df_in: pd.DataFrame, name: str):\n",
    "    df = df_in.copy()\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    for c in df.columns:\n",
    "        if df[c].dtype == 'object':\n",
    "            conv = pd.to_numeric(df[c], errors='coerce')\n",
    "            if conv.isna().all():\n",
    "                codes, _ = pd.factorize(df[c].astype(str))\n",
    "                df[c] = codes.astype('int32')\n",
    "            else:\n",
    "                df[c] = conv\n",
    "        elif str(df[c].dtype).startswith('Int'):\n",
    "            df[c] = df[c].astype('float32')\n",
    "    nan_total = int(df.isna().sum().sum())\n",
    "    if nan_total > 0:\n",
    "        df.fillna(-1, inplace=True)\n",
    "    df = df.astype('float32')\n",
    "    print(f\"[Diag] {name}: shape={df.shape}, nan_filled={nan_total}, dtypes_ok={all(np.issubdtype(t, np.number) for t in df.dtypes)}\")\n",
    "    return df\n",
    "\n",
    "X_train_clean = _clean_features(X_train, 'train')\n",
    "X_test_clean  = _clean_features(X_test, 'test')\n",
    "\n",
    "GRAD_DAMP = 0.8\n",
    "\n",
    "def quantile_objective(y_pred: np.ndarray, dtrain: xgb.DMatrix):\n",
    "    y_true = dtrain.get_label()\n",
    "    diff = y_true - y_pred\n",
    "    base_grad = np.where(diff > 0, -q, 1 - q).astype(np.float32)\n",
    "    grad = base_grad * GRAD_DAMP\n",
    "    hess = np.full_like(grad, 5e-6, dtype=np.float32)\n",
    "    return grad, hess\n",
    "\n",
    "# Eval-funksjon brukt i manuell loop\n",
    "\n",
    "def quantile_loss(y_true, y_hat, q=0.2):\n",
    "    d = y_true - y_hat\n",
    "    return float(np.mean(np.where(d > 0, q * d, (1 - q) * (-d))))\n",
    "\n",
    "# Sample weights\n",
    "p85 = np.percentile(Y_train, 85)\n",
    "p95 = np.percentile(Y_train, 95)\n",
    "sample_weight = np.ones_like(Y_train, dtype=float)\n",
    "sample_weight[Y_train > p85] = 0.7\n",
    "sample_weight[Y_train > p95] = 0.5\n",
    "\n",
    "train_mat = xgb.DMatrix(X_train_clean.values, label=Y_train, weight=sample_weight, feature_names=list(X_train_clean.columns))\n",
    "valid_mat = xgb.DMatrix(X_test_clean.values,  label=Y_test,  feature_names=list(X_test_clean.columns))\n",
    "\n",
    "params = {\n",
    "    \"eta\": 0.03,\n",
    "    \"max_depth\": 5,\n",
    "    \"min_child_weight\": 11,\n",
    "    \"subsample\": 0.65,\n",
    "    \"colsample_bytree\": 0.65,\n",
    "    \"gamma\": 0.6,\n",
    "    \"lambda\": 5.0,\n",
    "    \"alpha\": 1.0,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"objective\": \"reg:squarederror\",  # placeholder\n",
    "    \"base_score\": float(np.quantile(Y_train, q) * 0.95),\n",
    "    \"seed\": 42,\n",
    "}\n",
    "\n",
    "num_round = 1600\n",
    "patience = 120\n",
    "best_iter = -1\n",
    "best_loss = math.inf\n",
    "best_raw_model = None\n",
    "val_history = []\n",
    "train_history = []\n",
    "no_improve = 0\n",
    "\n",
    "# Manuell boosting loop (1 iterasjon av gangen) for å kunne evaluere kvantiltap eksplisitt\n",
    "bst = None\n",
    "for i in range(num_round):\n",
    "    try:\n",
    "        bst = xgb.train(\n",
    "            params=params,\n",
    "            dtrain=train_mat,\n",
    "            num_boost_round=1,\n",
    "            xgb_model=bst,\n",
    "            obj=quantile_objective,\n",
    "            verbose_eval=False,\n",
    "        )\n",
    "    except Exception as e:\n",
    "        print(f\"[FEIL] Iterasjon {i} under trening:\", e)\n",
    "        traceback.print_exc()\n",
    "        raise\n",
    "\n",
    "    # Prediksjoner for eval\n",
    "    pred_val = bst.predict(valid_mat)\n",
    "    pred_trn = bst.predict(train_mat)\n",
    "    loss_val = quantile_loss(Y_test, pred_val, q)\n",
    "    loss_trn = quantile_loss(Y_train, pred_trn, q)\n",
    "    val_history.append(loss_val)\n",
    "    train_history.append(loss_trn)\n",
    "\n",
    "    # Early stopping logikk\n",
    "    if loss_val + 1e-10 < best_loss:  # liten margin for numerisk støy\n",
    "        best_loss = loss_val\n",
    "        best_iter = i\n",
    "        best_raw_model = bst.save_raw()\n",
    "        no_improve = 0\n",
    "    else:\n",
    "        no_improve += 1\n",
    "\n",
    "    if (i + 1) % 100 == 0 or i == 0:\n",
    "        print(f\"Iter {i:4d} | val_q20_loss={loss_val:.6f} | train_q20_loss={loss_trn:.6f} | best={best_loss:.6f} (iter {best_iter})\")\n",
    "    if no_improve >= patience:\n",
    "        print(f\"[EarlyStopping] Ingen forbedring siste {patience} runder. Stopper ved iter {i}.\")\n",
    "        break\n",
    "\n",
    "if best_raw_model is not None and best_iter != i:\n",
    "    # Last tilbake beste modelltilstand\n",
    "    bst = xgb.Booster(params=params)\n",
    "    bst.load_model(bytearray(best_raw_model))\n",
    "\n",
    "print(f\"Best iteration: {best_iter}  (val_q20_loss={best_loss:.6f})\")\n",
    "\n",
    "# Prediksjon med beste modell\n",
    "try:\n",
    "    y_pred_raw = bst.predict(valid_mat)\n",
    "except Exception as e:\n",
    "    print(\"[FEIL] Under slutt-prediksjon:\", e)\n",
    "    traceback.print_exc()\n",
    "    raise\n",
    "\n",
    "BIAS_SHIFT = 0.985\n",
    "y_pred = y_pred_raw * BIAS_SHIFT\n",
    "upper_cap = np.percentile(Y_train, 99.7)\n",
    "y_pred = np.clip(y_pred, 0, upper_cap)\n",
    "\n",
    "final_val_loss = quantile_loss(Y_test, y_pred, q)\n",
    "print(f\"Revidert modell – kvantil-tap q={q}: {final_val_loss:.6f}\")\n",
    "\n",
    "baseline_const = np.full_like(Y_test, np.quantile(Y_train, q))\n",
    "print(\"Baseline (konstant) q-loss:\", quantile_loss(Y_test, baseline_const, q=q))\n",
    "if 'quantity' in X_test.columns:\n",
    "    baseline_quantity = 0.85 * X_test['quantity'].values\n",
    "    print(\"Baseline (0.85*quantity) q-loss:\", quantile_loss(Y_test, baseline_quantity, q=q))\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(Y_test, y_pred))\n",
    "print(\"RMSE (sekundær):\", rmse)\n",
    "\n",
    "under_ratio = (y_pred <= Y_test).mean()\n",
    "print(f\"Andel prediksjoner <= faktisk vekt: {under_ratio:.3f}\")\n",
    "\n",
    "# Siste 5 val-loss\n",
    "print(\"Siste 5 val_q20_loss:\", val_history[-5:])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "254d3a02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[AltModel] Starter treningsløp for sklearn GradientBoostingRegressor (quantile 0.2)\n",
      "[AltModel] GBR kvantil-tap q=0.2: 1269.060038\n",
      "[AltModel] Baseline (konstant) q-loss: 2596.3913899549475\n",
      "[AltModel] Baseline (0.85*quantity) q-loss: 267352.41462205903\n",
      "[AltModel] Andel prediksjoner <= faktisk vekt: 0.800\n",
      "[AltModel] Beregner produkt-basert ratio-baseline...\n",
      "[AltModel] Produkt-ratio baseline q20-loss: 2267.711037\n",
      "[AltModel] Ratio underestimeringsandel: 0.638\n",
      "[AltModel] GBR feature_importances_: {'rm_id': 0.10426, 'product_id': 0.14675, 'quantity': 0.59104, 'delivery_year': 0.05711, 'delivery_month': 0.01104, 'delivery_weekday': 0.0052, 'lead_time_days': 0.0846}\n"
     ]
    }
   ],
   "source": [
    "# Alternativ kvantil-modell: GradientBoostingRegressor (sklearn) + enkel ratio-baseline\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "print(\"[AltModel] Starter treningsløp for sklearn GradientBoostingRegressor (quantile 0.2)\")\n",
    "\n",
    "# Sikkerhetskopi / rensing dersom ikke kjørt tidligere\n",
    "if 'X_train_clean' not in globals():\n",
    "    def _quick_clean(df_in):\n",
    "        df = df_in.copy()\n",
    "        df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        num = df.select_dtypes(include=[np.number])\n",
    "        if num.shape[1] != df.shape[1]:\n",
    "            # Bruk faktoriser for ikke-numeriske\n",
    "            for c in df.columns:\n",
    "                if c not in num.columns:\n",
    "                    codes, _ = pd.factorize(df[c].astype(str))\n",
    "                    df[c] = codes\n",
    "        df.fillna(-1, inplace=True)\n",
    "        return df.astype('float32')\n",
    "    X_train_clean = _quick_clean(X_train)\n",
    "    X_test_clean  = _quick_clean(X_test)\n",
    "\n",
    "# GBR med kvantil-loss\n",
    "gbr = GradientBoostingRegressor(\n",
    "    loss='quantile',\n",
    "    alpha=0.2,\n",
    "    n_estimators=3000,\n",
    "    learning_rate=0.05,\n",
    "    max_depth=4,\n",
    "    min_samples_leaf=60,  # glatter\n",
    "    subsample=0.7,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "gbr.fit(X_train_clean, Y_train)\n",
    "\n",
    "pred_gbr_raw = gbr.predict(X_test_clean)\n",
    "BIAS_SHIFT_GBR = 0.985  # samme konservative justering\n",
    "pred_gbr = np.clip(pred_gbr_raw * BIAS_SHIFT_GBR, 0, np.percentile(Y_train, 99.5))\n",
    "\n",
    "# Kvantil-tap funksjon\n",
    "\n",
    "def quantile_loss(y_true, y_hat, q=0.2):\n",
    "    d = y_true - y_hat\n",
    "    return float(np.mean(np.where(d > 0, q * d, (1 - q) * (-d))))\n",
    "\n",
    "q_gbr = quantile_loss(Y_test, pred_gbr, q=0.2)\n",
    "print(f\"[AltModel] GBR kvantil-tap q=0.2: {q_gbr:.6f}\")\n",
    "\n",
    "baseline_const = np.full_like(Y_test, np.quantile(Y_train, 0.2))\n",
    "print(\"[AltModel] Baseline (konstant) q-loss:\", quantile_loss(Y_test, baseline_const, q=0.2))\n",
    "\n",
    "if 'quantity' in X_test.columns:\n",
    "    baseline_quantity = 0.85 * X_test['quantity'].values\n",
    "    print(\"[AltModel] Baseline (0.85*quantity) q-loss:\", quantile_loss(Y_test, baseline_quantity, q=0.2))\n",
    "\n",
    "under_ratio_gbr = (pred_gbr <= Y_test).mean()\n",
    "print(f\"[AltModel] Andel prediksjoner <= faktisk vekt: {under_ratio_gbr:.3f}\")\n",
    "\n",
    "# Enkel produkt-basert ratio-baseline (q20 av (net_weight/quantity) * framtidig quantity)\n",
    "print(\"[AltModel] Beregner produkt-basert ratio-baseline...\")\n",
    "train_df_tmp = X_train.copy()\n",
    "train_df_tmp['net_weight'] = Y_train\n",
    "# Unngå deling på null\n",
    "safe_quantity = np.clip(train_df_tmp['quantity'].values, 1e-6, None)\n",
    "ratio = train_df_tmp['net_weight'].values / safe_quantity\n",
    "train_df_tmp['ratio'] = ratio\n",
    "ratio_q20_per_prod = train_df_tmp.groupby('product_id')['ratio'].quantile(0.2)\n",
    "\n",
    "def ratio_predict(test_frame):\n",
    "    r = ratio_q20_per_prod.reindex(test_frame['product_id']).values\n",
    "    # fallback global q20 dersom NaN\n",
    "    global_q20 = np.quantile(ratio, 0.2)\n",
    "    r = np.where(np.isnan(r), global_q20, r)\n",
    "    return test_frame['quantity'].values * r\n",
    "\n",
    "ratio_pred = ratio_predict(X_test)\n",
    "ratio_pred = np.clip(ratio_pred, 0, np.percentile(Y_train, 99.5))\n",
    "q_ratio = quantile_loss(Y_test, ratio_pred, q=0.2)\n",
    "print(f\"[AltModel] Produkt-ratio baseline q20-loss: {q_ratio:.6f}\")\n",
    "print(f\"[AltModel] Ratio underestimeringsandel: {(ratio_pred <= Y_test).mean():.3f}\")\n",
    "\n",
    "# Feature importance (GBR)\n",
    "fi = gbr.feature_importances_\n",
    "fi_map = {col: round(float(val), 5) for col, val in zip(X_train_clean.columns, fi)}\n",
    "print(\"[AltModel] GBR feature_importances_:\", fi_map)\n",
    "\n",
    "# Velg hvilken prediksjon som skal brukes nedstrøms (sett y_pred_gbr som standard)\n",
    "y_pred_gbr = pred_gbr  # kan refereres i scoring-cell hvis ønskelig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0fba0425",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quantile loss (q=0.2) – backtest jan–mai 2024: 450569.7955831535\n",
      "       ID  predicted_weight\n",
      "0  2124.0      1.943117e+04\n",
      "1  2125.0      3.163805e+04\n",
      "2  2129.0      1.015021e+05\n",
      "3  2130.0      8.532402e+06\n",
      "4  2131.0      1.336900e+05\n",
      "       ID     weight\n",
      "0  2124.0     7560.0\n",
      "1  2125.0    25000.0\n",
      "2  2129.0    69980.0\n",
      "3  2130.0  3549704.0\n",
      "4  2131.0   237344.0\n"
     ]
    }
   ],
   "source": [
    "from kaggle_metric import score, ParticipantVisibleError\n",
    "\n",
    "\n",
    "receivals[\"date_arrival\"] = pd.to_datetime(receivals[\"date_arrival\"], errors=\"coerce\", utc=True).dt.tz_localize(None)\n",
    "\n",
    "\n",
    "start = pd.Timestamp(\"2024-01-01\")\n",
    "end   = pd.Timestamp(\"2024-05-31 23:59:59\")\n",
    "solution = (receivals.loc[(receivals[\"date_arrival\"] >= start) & (receivals[\"date_arrival\"] <= end)]\n",
    "            .groupby(\"rm_id\", as_index=False)\n",
    "            .agg(weight=(\"net_weight\", \"sum\"))\n",
    "           ).rename(columns={\"rm_id\": \"ID\"})\n",
    "\n",
    "\n",
    "rm_col = \"rm_id_raw\" if \"rm_id_raw\" in test.columns else \"rm_id\"\n",
    "\n",
    "preds = pd.DataFrame({\n",
    "    \"ID\": test[rm_col].values,\n",
    "    \"predicted_weight\": np.clip(y_pred_gbr, 0, None)  \n",
    "})\n",
    "\n",
    "submission = preds.groupby(\"ID\", as_index=False).agg(predicted_weight=(\"predicted_weight\", \"sum\"))\n",
    "\n",
    "\n",
    "submission = solution[[\"ID\"]].merge(submission, on=\"ID\", how=\"left\")\n",
    "submission[\"predicted_weight\"] = submission[\"predicted_weight\"].fillna(0.0)\n",
    "\n",
    "\n",
    "try:\n",
    "    final_score = score(solution=solution, submission=submission, row_id_column_name=\"ID\")\n",
    "    print(\"Quantile loss (q=0.2) – backtest jan–mai 2024:\", final_score)\n",
    "except ParticipantVisibleError as e:\n",
    "    print(\"Scoring feilet:\", e)\n",
    "    \n",
    "\n",
    "print(submission.head())\n",
    "print(solution.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
