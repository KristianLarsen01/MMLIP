{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7116be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa3dfd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last inn data\n",
    "receivals = pd.read_csv(\"data/kernel/receivals.csv\", parse_dates=[\"date_arrival\"])\n",
    "purchase_orders = pd.read_csv(\"data/kernel/purchase_orders.csv\", parse_dates=[\"delivery_date\"])\n",
    "transportation = pd.read_csv(\"data/extended/transportation.csv\")\n",
    "materials = pd.read_csv(\"data/extended/materials.csv\")\n",
    "\n",
    "neg_orders = purchase_orders[purchase_orders['quantity'] <= 0]\n",
    "purchase_orders_clean = purchase_orders[purchase_orders['quantity'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1794d031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   purchase_order_id  purchase_order_item_no  delivered  n_receivals  \\\n",
      "0              363.0                    10.0     8860.0            1   \n",
      "1              363.0                    10.0     8860.0            1   \n",
      "2              363.0                    10.0     8860.0            1   \n",
      "3              363.0                    10.0     8860.0            1   \n",
      "4              363.0                    10.0     8860.0            1   \n",
      "5              363.0                    10.0     8860.0            1   \n",
      "6              363.0                    10.0     8860.0            1   \n",
      "7              363.0                    10.0     8860.0            1   \n",
      "8              363.0                    10.0     8860.0            1   \n",
      "9              363.0                    30.0    11540.0            1   \n",
      "\n",
      "              delivery_start               delivery_end  quantity  \\\n",
      "0  2012-07-10 10:40:00+02:00  2012-07-10 10:40:00+02:00  150000.0   \n",
      "1  2012-07-10 10:40:00+02:00  2012-07-10 10:40:00+02:00  150000.0   \n",
      "2  2012-07-10 10:40:00+02:00  2012-07-10 10:40:00+02:00  150000.0   \n",
      "3  2012-07-10 10:40:00+02:00  2012-07-10 10:40:00+02:00  150000.0   \n",
      "4  2012-07-10 10:40:00+02:00  2012-07-10 10:40:00+02:00  150000.0   \n",
      "5  2012-07-10 10:40:00+02:00  2012-07-10 10:40:00+02:00  150000.0   \n",
      "6  2012-07-10 10:40:00+02:00  2012-07-10 10:40:00+02:00  150000.0   \n",
      "7  2012-07-10 10:40:00+02:00  2012-07-10 10:40:00+02:00  150000.0   \n",
      "8  2012-07-10 10:40:00+02:00  2012-07-10 10:40:00+02:00  150000.0   \n",
      "9  2012-07-06 15:01:00+02:00  2012-07-12 14:36:00+02:00  150000.0   \n",
      "\n",
      "               delivery_date  product_id  product_version  \\\n",
      "0  2012-07-31 00:00:00+02:00    91900296                1   \n",
      "1  2012-07-31 00:00:00+02:00    91900296                1   \n",
      "2  2012-07-31 00:00:00+02:00    91900296                1   \n",
      "3  2012-07-31 00:00:00+02:00    91900296                1   \n",
      "4  2012-07-31 00:00:00+02:00    91900296                1   \n",
      "5  2012-07-31 00:00:00+02:00    91900296                1   \n",
      "6  2012-07-31 00:00:00+02:00    91900296                1   \n",
      "7  2012-07-31 00:00:00+02:00    91900296                1   \n",
      "8  2012-07-31 00:00:00+02:00    91900296                1   \n",
      "9  2012-07-31 00:00:00+02:00    91901050                1   \n",
      "\n",
      "                    created_date_time                  modified_date_time  \\\n",
      "0  2012-07-04 13:58:15.0000000 +00:00  2014-09-03 08:09:08.0000000 +00:00   \n",
      "1  2012-07-04 13:58:15.0000000 +00:00  2014-09-03 08:09:08.0000000 +00:00   \n",
      "2  2012-07-04 13:58:15.0000000 +00:00  2014-09-03 08:09:08.0000000 +00:00   \n",
      "3  2012-07-04 13:58:15.0000000 +00:00  2014-09-03 08:09:08.0000000 +00:00   \n",
      "4  2012-07-04 13:58:15.0000000 +00:00  2014-09-03 08:09:08.0000000 +00:00   \n",
      "5  2012-07-04 13:58:15.0000000 +00:00  2014-09-03 08:09:08.0000000 +00:00   \n",
      "6  2012-07-04 13:58:15.0000000 +00:00  2014-09-03 08:09:08.0000000 +00:00   \n",
      "7  2012-07-04 13:58:15.0000000 +00:00  2014-09-03 08:09:08.0000000 +00:00   \n",
      "8  2012-07-04 13:58:15.0000000 +00:00  2014-09-03 08:09:08.0000000 +00:00   \n",
      "9  2012-07-09 07:53:36.0000000 +00:00  2014-09-03 08:09:17.0000000 +00:00   \n",
      "\n",
      "   unit_id unit  status_id  status  delivery_ratio  extreme_flag   rm_id  \n",
      "0      NaN  NaN          2  Closed        0.059067         False   374.0  \n",
      "1      NaN  NaN          2  Closed        0.059067         False   379.0  \n",
      "2      NaN  NaN          2  Closed        0.059067         False  1842.0  \n",
      "3      NaN  NaN          2  Closed        0.059067         False  1907.0  \n",
      "4      NaN  NaN          2  Closed        0.059067         False  2155.0  \n",
      "5      NaN  NaN          2  Closed        0.059067         False  2156.0  \n",
      "6      NaN  NaN          2  Closed        0.059067         False  2157.0  \n",
      "7      NaN  NaN          2  Closed        0.059067         False  2158.0  \n",
      "8      NaN  NaN          2  Closed        0.059067         False  2159.0  \n",
      "9      NaN  NaN          2  Closed        0.076933         False     NaN  \n"
     ]
    }
   ],
   "source": [
    "# Summer receivals per ordrelinje\n",
    "receivals_grouped = receivals.groupby(\n",
    "    [\"purchase_order_id\", \"purchase_order_item_no\"]\n",
    ").agg(\n",
    "    delivered=(\"net_weight\", \"sum\"),\n",
    "    n_receivals=(\"receival_item_no\", \"nunique\"),   # antall del-leveranser\n",
    "    delivery_start=(\"date_arrival\", \"min\"),\n",
    "    delivery_end=(\"date_arrival\", \"max\")\n",
    ").reset_index()\n",
    "\n",
    "# Merge med purchase_orders\n",
    "merged = receivals_grouped.merge(\n",
    "    purchase_orders_clean,\n",
    "    on=[\"purchase_order_id\", \"purchase_order_item_no\"],\n",
    "    how=\"inner\"\n",
    ")\n",
    "\n",
    "# Beregn delivery ratio\n",
    "merged[\"delivery_ratio\"] = merged[\"delivered\"] / merged[\"quantity\"]\n",
    "\n",
    "# Threshold for \"ekstrem\"\n",
    "threshold = 10\n",
    "merged[\"extreme_flag\"] = merged[\"delivery_ratio\"] > threshold\n",
    "\n",
    "# Fjerner ekstreme observasjoner\n",
    "merged_clean = merged.loc[~merged[\"extreme_flag\"]].copy()\n",
    "merged_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Ta ut kun unike koblinger mellom product_id og rm_id\n",
    "materials_map = materials[[\"product_id\", \"rm_id\"]].drop_duplicates()\n",
    "\n",
    "# Merge inn i merged_clean\n",
    "merged_clean = merged_clean.merge(materials_map, on=\"product_id\", how=\"left\")\n",
    "\n",
    "print(merged_clean.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37d2cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = merged_clean.copy()\n",
    "\n",
    "for c in [\"delivery_date\", \"created_date_time\"]:\n",
    "    df[c] = pd.to_datetime(df[c], errors=\"coerce\", utc=True).dt.tz_localize(None)\n",
    "\n",
    "df[\"delivery_date\"] = pd.to_datetime(df[\"delivery_date\"], errors=\"coerce\")\n",
    "df[\"created_date_time\"] = pd.to_datetime(df[\"created_date_time\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "df[\"delivery_year\"]    = df[\"delivery_date\"].dt.year\n",
    "df[\"delivery_month\"]   = df[\"delivery_date\"].dt.month\n",
    "df[\"delivery_weekday\"] = df[\"delivery_date\"].dt.weekday\n",
    "df[\"lead_time_days\"] = (df[\"delivery_date\"] - df[\"created_date_time\"]).dt.days\n",
    "df[\"lead_time_days\"] = df[\"lead_time_days\"].clip(lower=0).fillna(df[\"lead_time_days\"].median())\n",
    "\n",
    "cat_cols = [\"product_id\", \"product_version\", \"rm_id\"]\n",
    "encoders = {}\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].astype(str).fillna(\"MISSING\")\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    encoders[col] = le\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88288d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"quantity\",\n",
    "    \"product_id\", \n",
    "    \"product_version\", \n",
    "    \"rm_id\",\n",
    "    \"delivery_month\", \n",
    "    \"delivery_weekday\",\n",
    "    \"lead_time_days\",\n",
    "]\n",
    "\n",
    "x = df[features].copy()\n",
    "y = df[\"delivered\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0827fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (237760, 7)  Test: (8548, 7)\n"
     ]
    }
   ],
   "source": [
    "train_mask = df[\"delivery_date\"] < pd.Timestamp(\"2024-01-01\")\n",
    "X_train, y_train = x[train_mask], y[train_mask]\n",
    "X_test,  y_test  = x[~train_mask], y[~train_mask]\n",
    "\n",
    "print(\"Train:\", X_train.shape, \" Test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a50a686c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 122349.68329345141\n",
      "Quantile loss (q=0.2): 17517.07342890465\n",
      "Baseline Quantile loss (q=0.2): 24599.471127749184\n"
     ]
    }
   ],
   "source": [
    "model = RandomForestRegressor(\n",
    "    n_estimators = 100, \n",
    "    random_state = 42,\n",
    "    max_depth= None,\n",
    "    n_jobs= -1\n",
    "    )\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "def quantile_loss(y_true, y_pred, q = 0.2):\n",
    "    diff = y_true - y_pred\n",
    "    return np.mean(np.maximum(q*diff, (1-q)*(-diff)))\n",
    "\n",
    "qloss = quantile_loss(y_test, y_pred, q=0.2)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"Quantile loss (q=0.2):\", qloss)\n",
    "\n",
    "baseline_pred = X_test[\"quantity\"].values\n",
    "print(\"Baseline Quantile loss (q=0.2):\", quantile_loss(y_test, baseline_pred, q=0.2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fba0425",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 0) Forutsetninger ---\n",
    "# - 'receivals' er lastet, og inneholder kolonnene: rm_id, net_weight, date_arrival\n",
    "# - 'merged_clean' er datasettet du brukte til modelltrening\n",
    "# - 'test' er delsettet av merged_clean med delivery_date i 2024 (samme rader som y_pred er beregnet for)\n",
    "# - 'y_pred' er modellens prediksjoner på 'test' (per ordrelinje)\n",
    "# - score() og ParticipantVisibleError er importert fra koden din\n",
    "\n",
    "# Tips: hvis du tidligere label-encodet rm_id, sørg for å ha en \"rå\" kopi før encoding:\n",
    "# df[\"rm_id_raw\"] = original rm_id før encoding. Hvis du ikke har det, bruk merged_clean[\"rm_id\"] direkte om den er ikke-encodet.\n",
    "\n",
    "# --- 1) Normaliser datoer til datetime uten tz (for robuste filtrer) ---\n",
    "receivals[\"date_arrival\"] = pd.to_datetime(receivals[\"date_arrival\"], errors=\"coerce\", utc=True).dt.tz_localize(None)\n",
    "\n",
    "# --- 2) Lag solution: faktisk levert (A) pr rm_id i jan–mai 2024 ---\n",
    "start = pd.Timestamp(\"2024-01-01\")\n",
    "end   = pd.Timestamp(\"2024-05-31 23:59:59\")\n",
    "solution = (receivals.loc[(receivals[\"date_arrival\"] >= start) & (receivals[\"date_arrival\"] <= end)]\n",
    "            .groupby(\"rm_id\", as_index=False)\n",
    "            .agg(weight=(\"net_weight\", \"sum\"))\n",
    "           ).rename(columns={\"rm_id\": \"ID\"})\n",
    "\n",
    "# --- 3) Lag submission: predikert vekt (F) pr rm_id i samme vindu ---\n",
    "# Sørg for at 'test' har en kolonne med den ekte rm_id (ikke-encodet). Hvis du bare har encodet verdi,\n",
    "# hent rm_id fra merged_clean før encoding, f.eks. via en ekstra kolonne 'rm_id_raw'.\n",
    "rm_col = \"rm_id_raw\" if \"rm_id_raw\" in test.columns else \"rm_id\"\n",
    "\n",
    "preds = pd.DataFrame({\n",
    "    \"ID\": test[rm_col].values,\n",
    "    \"predicted_weight\": np.clip(y_pred, 0, None)  # for sikkerhets skyld, ikke-negative\n",
    "})\n",
    "\n",
    "submission = preds.groupby(\"ID\", as_index=False).agg(predicted_weight=(\"predicted_weight\", \"sum\"))\n",
    "\n",
    "# --- 4) Sørg for at ALLE ID-er i solution finnes i submission (ellers feiler score()) ---\n",
    "# Konservativt valg: manglende ID-er får 0 som prediksjon\n",
    "submission = solution[[\"ID\"]].merge(submission, on=\"ID\", how=\"left\")\n",
    "submission[\"predicted_weight\"] = submission[\"predicted_weight\"].fillna(0.0)\n",
    "\n",
    "# --- 5) Kjør metrikken din ---\n",
    "try:\n",
    "    final_score = score(solution=solution, submission=submission, row_id_column_name=\"ID\")\n",
    "    print(\"Quantile loss (q=0.2) – backtest jan–mai 2024:\", final_score)\n",
    "except ParticipantVisibleError as e:\n",
    "    print(\"Scoring feilet:\", e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
