{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7116be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa3dfd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last inn data\n",
    "receivals = pd.read_csv(\"data/kernel/receivals.csv\", parse_dates=[\"date_arrival\"])\n",
    "purchase_orders = pd.read_csv(\"data/kernel/purchase_orders.csv\", parse_dates=[\"delivery_date\"])\n",
    "transportation = pd.read_csv(\"data/extended/transportation.csv\")\n",
    "materials = pd.read_csv(\"data/extended/materials.csv\")\n",
    "\n",
    "neg_orders = purchase_orders[purchase_orders['quantity'] <= 0]\n",
    "purchase_orders_clean = purchase_orders[purchase_orders['quantity'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b4cac93e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [rm_id, product_id, purchase_order_id, purchase_order_item_no, receival_item_no, batch_id, date_arrival, receival_status, net_weight, supplier_id]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "neg_rec = receivals[receivals['net_weight'] <= 0]\n",
    "receivals_clean = receivals[receivals['net_weight'] > 0]\n",
    "\n",
    "print(receivals[receivals['purchase_order_id'] == 267468])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "973919a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3191\n"
     ]
    }
   ],
   "source": [
    "# unique purchase_order_id in receivals\n",
    "print(len(purchase_orders_clean[purchase_orders_clean['status'] == 'Deleted']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "1794d031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordre (rå): (7171, 11) - Etter ekstremfilter: (7150, 11)\n",
      "   purchase_order_id  ordered_quantity  delivered_total  n_lines  \\\n",
      "0                363          300000.0          20400.0        2   \n",
      "1                365          150000.0           2460.0        1   \n",
      "2                370          150000.0           6340.0        1   \n",
      "3             206172          640660.0         107270.0        2   \n",
      "4             208490         1701000.0         918561.0        2   \n",
      "5             208532         5093550.0        2248369.0        5   \n",
      "6             208533         1000000.0         501775.0        3   \n",
      "7             208535         6600000.0        2521945.0        4   \n",
      "8             208537         8975000.0        3527250.0        4   \n",
      "9             208538         1000000.0         434980.0        1   \n",
      "\n",
      "   n_lines_with_delivery                  time_created_order status_po  \\\n",
      "0                      2  2012-07-04 13:58:15.0000000 +00:00    Closed   \n",
      "1                      1  2012-07-04 14:12:02.0000000 +00:00    Closed   \n",
      "2                      1  2012-07-09 07:55:04.0000000 +00:00    Closed   \n",
      "3                      2  2003-04-15 16:34:06.0000000 +00:00    Closed   \n",
      "4                      2  2004-01-09 09:33:01.0000000 +00:00    Closed   \n",
      "5                      5  2004-01-13 13:32:30.0000000 +00:00    Closed   \n",
      "6                      3  2004-01-13 13:32:31.0000000 +00:00    Closed   \n",
      "7                      4  2004-01-13 13:32:32.0000000 +00:00    Closed   \n",
      "8                      4  2004-01-13 14:34:17.0000000 +00:00    Closed   \n",
      "9                      1  2004-01-13 14:34:18.0000000 +00:00    Closed   \n",
      "\n",
      "   n_unique_rm_ids  delivery_ratio  line_delivery_fraction  extreme_flag  \\\n",
      "0                2        0.068000                     1.0         False   \n",
      "1                1        0.016400                     1.0         False   \n",
      "2                1        0.042267                     1.0         False   \n",
      "3                2        0.167437                     1.0         False   \n",
      "4                2        0.540012                     1.0         False   \n",
      "5                5        0.441415                     1.0         False   \n",
      "6                3        0.501775                     1.0         False   \n",
      "7                4        0.382113                     1.0         False   \n",
      "8                4        0.393008                     1.0         False   \n",
      "9                1        0.434980                     1.0         False   \n",
      "\n",
      "                                         product_ids  \\\n",
      "0                               [91900296, 91901050]   \n",
      "1                                         [91901050]   \n",
      "2                                         [91901050]   \n",
      "3                               [91900143, 91900302]   \n",
      "4                               [91900143, 91900302]   \n",
      "5  [91900143, 91900146, 91900160, 91900302, 91900...   \n",
      "6                     [91900143, 91900302, 91900330]   \n",
      "7           [91900143, 91900160, 91900302, 91900330]   \n",
      "8           [91900143, 91900146, 91900160, 91900330]   \n",
      "9                                         [91900143]   \n",
      "\n",
      "                                rm_ids  \n",
      "0                     [2159.0, 2182.0]  \n",
      "1                             [2182.0]  \n",
      "2                             [2182.0]  \n",
      "3                       [367.0, 375.0]  \n",
      "4                       [365.0, 375.0]  \n",
      "5  [365.0, 366.0, 369.0, 375.0, 389.0]  \n",
      "6                [367.0, 375.0, 389.0]  \n",
      "7         [365.0, 366.0, 375.0, 389.0]  \n",
      "8         [365.0, 366.0, 369.0, 389.0]  \n",
      "9                              [365.0]  \n"
     ]
    }
   ],
   "source": [
    "# ORDRE-NIVÅ (B): Aggregér leveranser og bestillinger til ett rad per purchase_order_id\n",
    "# 1. Linjenivå: start fra purchase_orders_clean (kun quantity > 0 allerede filtrert)\n",
    "line_base = purchase_orders_clean[\n",
    "    [\n",
    "        \"purchase_order_id\",\n",
    "        \"purchase_order_item_no\",\n",
    "        \"quantity\",\n",
    "        \"product_id\",\n",
    "        \"product_version\",\n",
    "        \"status\",\n",
    "        \"created_date_time\"\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "# 2. Leveranser per ordrelinje (kun positive net_weight i receivals_clean)\n",
    "receivals_line = (\n",
    "    receivals_clean\n",
    "    .groupby([\"purchase_order_id\", \"purchase_order_item_no\"], as_index=False)\n",
    "    .agg(\n",
    "        delivered=(\"net_weight\", \"sum\"),\n",
    "        n_receivals=(\"receival_item_no\", \"nunique\"),\n",
    "        delivery_start=(\"date_arrival\", \"min\"),\n",
    "        \n",
    "        rm_id_line=(\"rm_id\", \"first\")  # antar én rm_id per linje\n",
    "    )\n",
    ")\n",
    "\n",
    "# 3. Slå sammen slik at også u-leverte linjer beholdes\n",
    "line_df = line_base.merge(\n",
    "    receivals_line,\n",
    "    on=[\"purchase_order_id\", \"purchase_order_item_no\"],\n",
    "    how=\"inner\",\n",
    "    validate=\"one_to_one\"\n",
    ")\n",
    "\n",
    "# 4. Fyll manglende leveranser med 0 og sikre typer\n",
    "line_df[\"delivered\"] = line_df[\"delivered\"].fillna(0.0)\n",
    "line_df[\"n_receivals\"] = line_df[\"n_receivals\"].fillna(0).astype(int)\n",
    "\n",
    "# --- Viktig: normaliser datoer før aggregasjon (hindrer TypeError ved min/max over blandede typer) ---\n",
    "\"\"\" for c in [\"delivery_start\", \"delivery_end\"]:\n",
    "    line_df[c] = pd.to_datetime(line_df[c], errors=\"coerce\", utc=True).dt.tz_localize(None) \"\"\"\n",
    "\n",
    "# 5. Linje-fill rate (leverte kg / bestilt kg)\n",
    "line_df[\"line_fill_ratio\"] = line_df[\"delivered\"] / line_df[\"quantity\"]\n",
    "\n",
    "# 6. Ordrenivå-aggregat (en rad per purchase_order_id) – bruk de normaliserte datoene\n",
    "order_level = (\n",
    "    line_df\n",
    "    .groupby(\"purchase_order_id\", as_index=False)\n",
    "    .agg(\n",
    "        ordered_quantity=(\"quantity\", \"sum\"),\n",
    "        delivered_total=(\"delivered\", \"sum\"),\n",
    "        n_lines=(\"purchase_order_item_no\", \"nunique\"),\n",
    "        n_lines_with_delivery=(\"delivered\", lambda s: (s > 0).sum()),\n",
    "        time_created_order=(\"created_date_time\", \"min\"),\n",
    "        status_po=(\"status\", \"first\"),\n",
    "        n_unique_rm_ids=(\"rm_id_line\", \"nunique\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# 7. Ordre-fill ratio + andel linjer med leveranse\n",
    "order_level[\"delivery_ratio\"] = order_level[\"delivered_total\"] / order_level[\"ordered_quantity\"]\n",
    "order_level[\"line_delivery_fraction\"] = order_level[\"n_lines_with_delivery\"] / order_level[\"n_lines\"]\n",
    "\n",
    "# 8. Ekstremfilter (valgfritt): fjern åpenbart urimelige ratioer\n",
    "threshold = 10\n",
    "order_level[\"extreme_flag\"] = order_level[\"delivery_ratio\"] > threshold\n",
    "order_clean = order_level.loc[~order_level[\"extreme_flag\"]].copy()\n",
    "order_clean.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# 9. (Valgfritt) Berik med rm_id / product mapping.\n",
    "product_agg = (\n",
    "    line_df.groupby(\"purchase_order_id\")\n",
    "    .agg(\n",
    "        product_ids=(\"product_id\", lambda s: list(sorted(set(s)))),\n",
    "        rm_ids=(\"rm_id_line\", lambda s: list(sorted(set(s.dropna()))))\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "order_enriched = order_clean.merge(product_agg, on=\"purchase_order_id\", how=\"left\")\n",
    "\n",
    "print(\"Ordre (rå):\", order_level.shape, \"- Etter ekstremfilter:\", order_clean.shape)\n",
    "print(order_enriched.head(10))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d2cc07",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'delivery_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\strom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'delivery_date'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m df \u001b[38;5;241m=\u001b[39m order_enriched\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelivery_date\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated_date_time\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m----> 4\u001b[0m     df[c] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43mc\u001b[49m\u001b[43m]\u001b[49m, errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m\"\u001b[39m, utc\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mdt\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m      6\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelivery_date\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelivery_date\u001b[39m\u001b[38;5;124m\"\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      7\u001b[0m df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated_date_time\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcreated_date_time\u001b[39m\u001b[38;5;124m\"\u001b[39m], errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoerce\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\strom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Users\\strom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'delivery_date'"
     ]
    }
   ],
   "source": [
    "df = order_enriched.copy()\n",
    "\n",
    "for c in [\"delivery_start\", \"created_date_time\"]:\n",
    "    df[c] = pd.to_datetime(df[c], errors=\"coerce\", utc=True).dt.tz_localize(None)\n",
    "\n",
    "df[\"delivery_date\"] = pd.to_datetime(df[\"delivery_date\"], errors=\"coerce\")\n",
    "df[\"created_date_time\"] = pd.to_datetime(df[\"created_date_time\"], errors=\"coerce\")\n",
    "\n",
    "\n",
    "df[\"delivery_year\"]    = df[\"delivery_date\"].dt.year\n",
    "df[\"delivery_month\"]   = df[\"delivery_date\"].dt.month\n",
    "df[\"delivery_weekday\"] = df[\"delivery_date\"].dt.weekday\n",
    "df[\"lead_time_days\"] = (df[\"delivery_start\"] - df[\"created_date_time\"]).dt.days\n",
    "df[\"lead_time_days\"] = df[\"lead_time_days\"].clip(lower=0).fillna(df[\"lead_time_days\"].median())\n",
    "\n",
    "# Fjern rmid med Nan\n",
    "df = df.dropna(subset=[\"rm_id\"])\n",
    "\n",
    "cat_cols = [\"product_id\", \"product_version\"]\n",
    "encoders = {}\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].astype(str).fillna(\"MISSING\")\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    encoders[col] = le\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88288d47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' features = [\\n    \"quantity\",\\n    \"product_id\", \\n    \"product_version\", \\n    \"rm_id\",\\n    \"delivery_year\",\\n    \"delivery_month\", \\n    \"delivery_weekday\",\\n    \"lead_time_days\",\\n]\\n\\nx = df[features].copy()\\ny = df[\"delivered\"].values '"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = [\n",
    "    \"ordered_quantity\",\n",
    "    \"delivered_total\",  \n",
    "    \"rm_id\",\n",
    "    \"delivery_year\",\n",
    "    \"delivery_month\", \n",
    "    \"delivery_weekday\",\n",
    "    \"lead_time_days\",\n",
    "    \"product_id\",\n",
    "    \"delivery_ratio\",\n",
    "]\n",
    "\n",
    "x = df[features].copy()\n",
    "y = df[\"delivered_total\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0827fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' train_mask = df[\"delivery_date\"] < pd.Timestamp(\"2024-01-01\")\\n\\nX_train, y_train = x[train_mask], y[train_mask]\\nX_test,  y_test  = x[~train_mask], y[~train_mask]\\n\\n# Behold ID-informasjonen også\\ntest = df.loc[~train_mask].copy()\\n\\nprint(X_test.head(10)) '"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" train_mask = df[\"delivery_date\"] < pd.Timestamp(\"2024-01-01\")\n",
    "\n",
    "X_train, y_train = x[train_mask], y[train_mask]\n",
    "X_test,  y_test  = x[~train_mask], y[~train_mask]\n",
    "\n",
    "# Behold ID-informasjonen også\n",
    "test = df.loc[~train_mask].copy()\n",
    "\n",
    "print(X_test.head(10)) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a50a686c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' model = GradientBoostingRegressor(\\n    n_estimators=1000,\\n    random_state=42,\\n    learning_rate = 0.01,\\n    loss = \\'absolute_error\\',\\n    subsample = 0.1,\\n    max_features = \\'log2\\',\\n    \\n\\n)  \\nmodel.fit(X_train, y_train)\\ny_pred = model.predict(X_test)\\n\\nrmse = np.sqrt(mean_squared_error(y_test, y_pred))\\n\\ndef quantile_loss(y_true, y_pred, q = 0.2):\\n    diff = y_true - y_pred\\n    return np.mean(np.maximum(q*diff, (1-q)*(-diff)))\\n\\nqloss = quantile_loss(y_test, y_pred, q=0.2)\\nprint(\"RMSE:\", rmse)\\nprint(\"Quantile loss (q=0.2):\", qloss)\\n\\nbaseline_pred = X_test[\"quantity\"].values\\nprint(\"Baseline Quantile loss (q=0.2):\", quantile_loss(y_test, baseline_pred, q=0.2))\\n '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" model = GradientBoostingRegressor(\n",
    "    n_estimators=1000,\n",
    "    random_state=42,\n",
    "    learning_rate = 0.01,\n",
    "    loss = 'absolute_error',\n",
    "    subsample = 0.1,\n",
    "    max_features = 'log2',\n",
    "    \n",
    "\n",
    ")  \n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "def quantile_loss(y_true, y_pred, q = 0.2):\n",
    "    diff = y_true - y_pred\n",
    "    return np.mean(np.maximum(q*diff, (1-q)*(-diff)))\n",
    "\n",
    "qloss = quantile_loss(y_test, y_pred, q=0.2)\n",
    "print(\"RMSE:\", rmse)\n",
    "print(\"Quantile loss (q=0.2):\", qloss)\n",
    "\n",
    "baseline_pred = X_test[\"quantity\"].values\n",
    "print(\"Baseline Quantile loss (q=0.2):\", quantile_loss(y_test, baseline_pred, q=0.2))\n",
    " \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0fba0425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from kaggle_metric import score, ParticipantVisibleError\\n\\n\\nreceivals[\"date_arrival\"] = pd.to_datetime(receivals[\"date_arrival\"], errors=\"coerce\", utc=True).dt.tz_localize(None)\\n\\n\\nstart = pd.Timestamp(\"2024-01-01\")\\nend   = pd.Timestamp(\"2024-05-31 23:59:59\")\\nsolution = (receivals.loc[(receivals[\"date_arrival\"] >= start) & (receivals[\"date_arrival\"] <= end)]\\n            .groupby(\"rm_id\", as_index=False)\\n            .agg(weight=(\"net_weight\", \"sum\"))\\n           ).rename(columns={\"rm_id\": \"ID\"})\\n\\n\\nrm_col = \"rm_id_raw\" if \"rm_id_raw\" in test.columns else \"rm_id\"\\n\\npreds = pd.DataFrame({\\n    \"ID\": test[rm_col].values,\\n    \"predicted_weight\": np.clip(y_pred, 0, None)  \\n})\\n\\nsubmission = preds.groupby(\"ID\", as_index=False).agg(predicted_weight=(\"predicted_weight\", \"sum\"))\\n\\n\\nsubmission = solution[[\"ID\"]].merge(submission, on=\"ID\", how=\"left\")\\nsubmission[\"predicted_weight\"] = submission[\"predicted_weight\"].fillna(0.0)\\n\\n\\ntry:\\n    final_score = score(solution=solution, submission=submission, row_id_column_name=\"ID\")\\n    print(\"Quantile loss (q=0.2) – backtest jan–mai 2024:\", final_score)\\nexcept ParticipantVisibleError as e:\\n    print(\"Scoring feilet:\", e)\\n    \\n\\nprint(submission.head())\\nprint(solution.head()) '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from kaggle_metric import score, ParticipantVisibleError\n",
    "\n",
    "\n",
    "receivals[\"date_arrival\"] = pd.to_datetime(receivals[\"date_arrival\"], errors=\"coerce\", utc=True).dt.tz_localize(None)\n",
    "\n",
    "\n",
    "start = pd.Timestamp(\"2024-01-01\")\n",
    "end   = pd.Timestamp(\"2024-05-31 23:59:59\")\n",
    "solution = (receivals.loc[(receivals[\"date_arrival\"] >= start) & (receivals[\"date_arrival\"] <= end)]\n",
    "            .groupby(\"rm_id\", as_index=False)\n",
    "            .agg(weight=(\"net_weight\", \"sum\"))\n",
    "           ).rename(columns={\"rm_id\": \"ID\"})\n",
    "\n",
    "\n",
    "rm_col = \"rm_id_raw\" if \"rm_id_raw\" in test.columns else \"rm_id\"\n",
    "\n",
    "preds = pd.DataFrame({\n",
    "    \"ID\": test[rm_col].values,\n",
    "    \"predicted_weight\": np.clip(y_pred, 0, None)  \n",
    "})\n",
    "\n",
    "submission = preds.groupby(\"ID\", as_index=False).agg(predicted_weight=(\"predicted_weight\", \"sum\"))\n",
    "\n",
    "\n",
    "submission = solution[[\"ID\"]].merge(submission, on=\"ID\", how=\"left\")\n",
    "submission[\"predicted_weight\"] = submission[\"predicted_weight\"].fillna(0.0)\n",
    "\n",
    "\n",
    "try:\n",
    "    final_score = score(solution=solution, submission=submission, row_id_column_name=\"ID\")\n",
    "    print(\"Quantile loss (q=0.2) – backtest jan–mai 2024:\", final_score)\n",
    "except ParticipantVisibleError as e:\n",
    "    print(\"Scoring feilet:\", e)\n",
    "    \n",
    "\n",
    "print(submission.head())\n",
    "print(solution.head()) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
