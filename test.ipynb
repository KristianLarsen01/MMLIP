{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7116be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fe71a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   rm_id  purchase_order_id  purchase_order_item_no  product_id  \\\n",
      "0  365.0           208545.0                    10.0  91900143.0   \n",
      "1  365.0           208545.0                    10.0  91900143.0   \n",
      "2  365.0           208490.0                    10.0  91900143.0   \n",
      "3  365.0           208490.0                    10.0  91900143.0   \n",
      "4  379.0           210435.0                    20.0  91900296.0   \n",
      "5  389.0           208535.0                    30.0  91900330.0   \n",
      "6  365.0           208532.0                    10.0  91900143.0   \n",
      "7  369.0           208532.0                    30.0  91900146.0   \n",
      "8  366.0           208532.0                    20.0  91900160.0   \n",
      "9  365.0           208537.0                    10.0  91900143.0   \n",
      "\n",
      "                date_arrival  net_weight   quantity         created_date_time  \n",
      "0  2004-06-15 13:34:00+02:00     11420.0  1975000.0 2004-01-13 15:30:57+00:00  \n",
      "1  2004-06-15 13:34:00+02:00     13760.0  1975000.0 2004-01-13 15:30:57+00:00  \n",
      "2  2004-06-15 13:38:00+02:00     11281.0  1500000.0 2004-01-09 09:33:01+00:00  \n",
      "3  2004-06-15 13:38:00+02:00     13083.0  1500000.0 2004-01-09 09:33:01+00:00  \n",
      "4  2004-06-15 13:40:00+02:00     23910.0   125000.0 2004-06-24 16:33:45+00:00  \n",
      "5  2004-06-15 13:43:00+02:00      8680.0   350000.0 2004-01-13 13:32:32+00:00  \n",
      "6  2004-06-15 13:46:00+02:00     14840.0  3500000.0 2004-01-13 13:32:30+00:00  \n",
      "7  2004-06-15 13:46:00+02:00      6745.0   600000.0 2004-01-13 13:32:30+00:00  \n",
      "8  2004-06-15 13:46:00+02:00      3015.0   600000.0 2004-01-13 13:32:30+00:00  \n",
      "9  2004-06-16 08:26:00+02:00     25060.0  6575000.0 2004-01-13 14:34:17+00:00  \n"
     ]
    }
   ],
   "source": [
    "# Last inn data\n",
    "purchase_orders = pd.read_csv(\"data/kernel/purchase_orders.csv\", parse_dates=[\"delivery_date\", \"created_date_time\", \"modified_date_time\"])\n",
    "receivals = pd.read_csv(\"data/kernel/receivals.csv\", parse_dates=[\"date_arrival\"])\n",
    "raw_material = pd.read_csv(\"data/extended/materials.csv\")\n",
    "transportation = pd.read_csv(\"data/extended/transportation.csv\")\n",
    "\n",
    "\n",
    "purchase_orders_clean = purchase_orders[purchase_orders['quantity'] > 0]\n",
    "purchase_orders_clean = purchase_orders_clean[purchase_orders_clean['status'] != 'Deleted']\n",
    "receivals_clean = receivals[receivals['net_weight'] > 0]\n",
    "\n",
    "purchase_base = purchase_orders_clean[[\"purchase_order_id\", \n",
    "                                       \"quantity\",\n",
    "                                       \"created_date_time\",\n",
    "                                       \"purchase_order_item_no\",\n",
    "                                       ]]\n",
    "\n",
    "receivals_base = receivals_clean[[\"rm_id\",\n",
    "                                 \"purchase_order_id\",\n",
    "                                 \"purchase_order_item_no\",\n",
    "                                 \"product_id\",\n",
    "                                 \"date_arrival\",\n",
    "                                 \"net_weight\"\n",
    "                                 ]]\n",
    "\n",
    "rec_ord_merged = receivals_base.merge(\n",
    "    purchase_base,\n",
    "    on = [\"purchase_order_id\", \"purchase_order_item_no\"],\n",
    "    how = \"inner\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ccec5e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = rec_ord_merged.copy()\n",
    "\n",
    "for c in [\"date_arrival\", \"created_date_time\"]:\n",
    "    df[c] = pd.to_datetime(df[c], errors=\"coerce\", utc=True).dt.tz_localize(None)\n",
    "    \n",
    "df[\"delivery_year\"]    = df[\"date_arrival\"].dt.year\n",
    "df[\"delivery_month\"]   = df[\"date_arrival\"].dt.month\n",
    "df[\"delivery_weekday\"] = df[\"date_arrival\"].dt.weekday\n",
    "df[\"lead_time_days\"] = (df[\"date_arrival\"] - df[\"created_date_time\"]).dt.days\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "48a41be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_diff = df[\"net_weight\"] - df[\"quantity\"]\n",
    "df[\"delivery_ratio\"] = df[\"net_weight\"] / df[\"quantity\"]\n",
    "\n",
    "features = [\n",
    "    'rm_id',\n",
    "    'product_id',\n",
    "    'created_date_time',\n",
    "    'net_weight',\n",
    "    'quantity',\n",
    "    'date_arrival',\n",
    "    'delivery_year',\n",
    "    'delivery_month',\n",
    "    'delivery_weekday',\n",
    "    'lead_time_days',\n",
    "    'weight_diff',\n",
    "    'delivery_ratio'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5efebf0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "1794d031",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' # Features vi vil ha fra purchase_orders\\npurchase_orders_base = purchase_orders_clean[\\n    [\\n        \"purchase_order_id\",\\n        \"purchase_order_item_no\",\\n        \"quantity\",\\n        \"product_id\",\\n        \"product_version\",\\n        \"status\",\\n        \"created_date_time\"\\n    ]\\n].copy()\\n\\n# Leveranser per ordrelinje\\nreceivals_grouped_by_lines = (\\n    receivals_clean\\n    .groupby([\"purchase_order_id\", \"purchase_order_item_no\"], as_index=False)\\n    .agg(\\n        delivered=(\"net_weight\", \"sum\"),\\n        n_receivals=(\"receival_item_no\", \"nunique\"),\\n        delivery_start=(\"date_arrival\", \"min\"),\\n        rm_id_line=(\"rm_id\", \"first\")  \\n    )\\n)\\n\\n# Slår sammen purchase_orders med leveranser per linje\\npur_rec_merged_by_line = purchase_orders_base.merge(\\n    receivals_grouped_by_lines,\\n    on=[\"purchase_order_id\", \"purchase_order_item_no\"],\\n    how=\"inner\",\\n    validate=\"one_to_one\"\\n)\\n\\n# Fyll manglende leveranser med 0 og sikre typer\\npur_rec_merged_by_line[\"delivered\"] = pur_rec_merged_by_line[\"delivered\"].fillna(0.0)\\npur_rec_merged_by_line[\"n_receivals\"] = pur_rec_merged_by_line[\"n_receivals\"].fillna(0).astype(int)\\n\\n# 5. Linje-fill rate (leverte kg / bestilt kg)\\npur_rec_merged_by_line[\"line_fill_ratio\"] = pur_rec_merged_by_line[\"delivered\"] / pur_rec_merged_by_line[\"quantity\"]\\n\\n# --- Ny aggregering: per (purchase_order_id, rm_id_line) ---\\norder_rm = (\\n    pur_rec_merged_by_line\\n    .dropna(subset=[\"rm_id_line\"])  # hvis noen linjer mangler rm_id\\n    .groupby([\"purchase_order_id\", \"rm_id_line\"], as_index=False)\\n    .agg(\\n        ordered_quantity=(\"quantity\", \"first\"),\\n        delivered_total=(\"delivered\", \"sum\"),\\n        n_lines=(\"purchase_order_item_no\", \"nunique\"),\\n        n_lines_with_delivery=(\"delivered\", lambda s: (s > 0).sum()),\\n        time_created_order=(\"created_date_time\", \"min\"),\\n        time_first_delivery=(\"delivery_start\", \"min\"),\\n        status_po=(\"status\", \"first\"),\\n        # nyttig: saml unike product_ids for akkurat denne (PO, rm)-kombinasjonen\\n        product_ids=(\"product_id\", lambda s: sorted(set(s)))\\n    )\\n)\\n\\n# Ratioer på (PO, rm)-nivå\\norder_rm[\"delivery_ratio\"] = order_rm[\"delivered_total\"] / order_rm[\"ordered_quantity\"]\\norder_rm[\"line_delivery_fraction\"] = order_rm[\"n_lines_with_delivery\"] / order_rm[\"n_lines\"]\\n\\n# Ekstremfilter per (PO, rm)\\nthreshold = 10\\norder_rm[\"extreme_flag\"] = order_rm[\"delivery_ratio\"] > threshold\\norder_rm_clean = order_rm.loc[~order_rm[\"extreme_flag\"]].copy().reset_index(drop=True)\\n\\n# Ryddige kolonnenavn\\norder_rm_clean = order_rm_clean.rename(columns={\"rm_id_line\": \"rm_id\"})\\n\\nprint(order_rm_clean.head(10)) '"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" # Features vi vil ha fra purchase_orders\n",
    "purchase_orders_base = purchase_orders_clean[\n",
    "    [\n",
    "        \"purchase_order_id\",\n",
    "        \"purchase_order_item_no\",\n",
    "        \"quantity\",\n",
    "        \"product_id\",\n",
    "        \"product_version\",\n",
    "        \"status\",\n",
    "        \"created_date_time\"\n",
    "    ]\n",
    "].copy()\n",
    "\n",
    "# Leveranser per ordrelinje\n",
    "receivals_grouped_by_lines = (\n",
    "    receivals_clean\n",
    "    .groupby([\"purchase_order_id\", \"purchase_order_item_no\"], as_index=False)\n",
    "    .agg(\n",
    "        delivered=(\"net_weight\", \"sum\"),\n",
    "        n_receivals=(\"receival_item_no\", \"nunique\"),\n",
    "        delivery_start=(\"date_arrival\", \"min\"),\n",
    "        rm_id_line=(\"rm_id\", \"first\")  \n",
    "    )\n",
    ")\n",
    "\n",
    "# Slår sammen purchase_orders med leveranser per linje\n",
    "pur_rec_merged_by_line = purchase_orders_base.merge(\n",
    "    receivals_grouped_by_lines,\n",
    "    on=[\"purchase_order_id\", \"purchase_order_item_no\"],\n",
    "    how=\"inner\",\n",
    "    validate=\"one_to_one\"\n",
    ")\n",
    "\n",
    "# Fyll manglende leveranser med 0 og sikre typer\n",
    "pur_rec_merged_by_line[\"delivered\"] = pur_rec_merged_by_line[\"delivered\"].fillna(0.0)\n",
    "pur_rec_merged_by_line[\"n_receivals\"] = pur_rec_merged_by_line[\"n_receivals\"].fillna(0).astype(int)\n",
    "\n",
    "# 5. Linje-fill rate (leverte kg / bestilt kg)\n",
    "pur_rec_merged_by_line[\"line_fill_ratio\"] = pur_rec_merged_by_line[\"delivered\"] / pur_rec_merged_by_line[\"quantity\"]\n",
    "\n",
    "# --- Ny aggregering: per (purchase_order_id, rm_id_line) ---\n",
    "order_rm = (\n",
    "    pur_rec_merged_by_line\n",
    "    .dropna(subset=[\"rm_id_line\"])  # hvis noen linjer mangler rm_id\n",
    "    .groupby([\"purchase_order_id\", \"rm_id_line\"], as_index=False)\n",
    "    .agg(\n",
    "        ordered_quantity=(\"quantity\", \"first\"),\n",
    "        delivered_total=(\"delivered\", \"sum\"),\n",
    "        n_lines=(\"purchase_order_item_no\", \"nunique\"),\n",
    "        n_lines_with_delivery=(\"delivered\", lambda s: (s > 0).sum()),\n",
    "        time_created_order=(\"created_date_time\", \"min\"),\n",
    "        time_first_delivery=(\"delivery_start\", \"min\"),\n",
    "        status_po=(\"status\", \"first\"),\n",
    "        # nyttig: saml unike product_ids for akkurat denne (PO, rm)-kombinasjonen\n",
    "        product_ids=(\"product_id\", lambda s: sorted(set(s)))\n",
    "    )\n",
    ")\n",
    "\n",
    "# Ratioer på (PO, rm)-nivå\n",
    "order_rm[\"delivery_ratio\"] = order_rm[\"delivered_total\"] / order_rm[\"ordered_quantity\"]\n",
    "order_rm[\"line_delivery_fraction\"] = order_rm[\"n_lines_with_delivery\"] / order_rm[\"n_lines\"]\n",
    "\n",
    "# Ekstremfilter per (PO, rm)\n",
    "threshold = 10\n",
    "order_rm[\"extreme_flag\"] = order_rm[\"delivery_ratio\"] > threshold\n",
    "order_rm_clean = order_rm.loc[~order_rm[\"extreme_flag\"]].copy().reset_index(drop=True)\n",
    "\n",
    "# Ryddige kolonnenavn\n",
    "order_rm_clean = order_rm_clean.rename(columns={\"rm_id_line\": \"rm_id\"})\n",
    "\n",
    "print(order_rm_clean.head(10)) \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d2cc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\" cat_cols = [\"product_ids\"]\n",
    "encoders = {}\n",
    "for col in cat_cols:\n",
    "    df[col] = df[col].astype(str).fillna(\"MISSING\")\n",
    "    le = LabelEncoder()\n",
    "    df[col] = le.fit_transform(df[col])\n",
    "    encoders[col] = le \"\"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88288d47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features shape: (7150, 13)\n",
      "   ordered_quantity  delivered_total  delivery_ratio  line_delivery_fraction  \\\n",
      "0          300000.0          20400.0        0.068000                     1.0   \n",
      "1          150000.0           2460.0        0.016400                     1.0   \n",
      "2          150000.0           6340.0        0.042267                     1.0   \n",
      "3          640660.0         107270.0        0.167437                     1.0   \n",
      "4         1701000.0         918561.0        0.540012                     1.0   \n",
      "\n",
      "   n_rm_ids  n_product_ids  rm_ids_sig  product_ids_sig  lead_time_days  \\\n",
      "0         2              0    0.427668              0.0               1   \n",
      "1         1              0    0.214438              0.0               8   \n",
      "2         1              0    0.214438              0.0               3   \n",
      "3         2              0    0.809885              0.0             460   \n",
      "4         2              0    0.740628              0.0             158   \n",
      "\n",
      "   delivery_year  delivery_month  delivery_weekday  created_epoch_days  \n",
      "0           2012               7                 4        15525.582118  \n",
      "1           2012               7                 3        15525.591690  \n",
      "2           2012               7                 3        15530.329907  \n",
      "3           2004               7                 0        12157.690347  \n",
      "4           2004               6                 1        12426.397928  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\strom\\AppData\\Local\\Temp\\ipykernel_30508\\2344725399.py:23: FutureWarning: Series.view is deprecated and will be removed in a future version. Use ``astype`` as an alternative to change the dtype.\n",
      "  df['created_epoch_days'] = (df['created_date_time'].view('int64') // 10**9) / 86400.0\n"
     ]
    }
   ],
   "source": [
    "features = [\n",
    "    \"ordered_quantity\",\n",
    "    \"delivered_total\",  \n",
    "    \"rm_ids\",\n",
    "    \"delivery_year\",\n",
    "    \"delivery_month\", \n",
    "    \"delivery_weekday\",\n",
    "    \"lead_time_days\",\n",
    "    \"product_ids\",\n",
    "    \"delivery_ratio\",\n",
    "    \"created_date_time\"\n",
    "]\n",
    "\n",
    "x = df[features].copy()\n",
    "y = df[\"delivered_total\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f0827fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ordered_quantity  delivered_total                    rm_ids  \\\n",
      "6580           25000.0          24452.0                  [2130.0]   \n",
      "6661            3240.0           3240.0                  [2124.0]   \n",
      "6662          150000.0         140580.0                  [2741.0]   \n",
      "6663          400000.0         388940.0                  [3125.0]   \n",
      "6664          225000.0         230400.0                  [3126.0]   \n",
      "...                ...              ...                       ...   \n",
      "6766           65000.0         164637.0  [2142.0, 2144.0, 2145.0]   \n",
      "6767          300000.0         705674.0                  [3781.0]   \n",
      "6768           25000.0          24236.0                  [3362.0]   \n",
      "6769           25000.0          95040.0                  [3865.0]   \n",
      "6770          300000.0         122967.0                  [3781.0]   \n",
      "\n",
      "      delivery_year  delivery_month  delivery_weekday  lead_time_days  \\\n",
      "6580           2024               1                 4             116   \n",
      "6661           2024               1                 0              38   \n",
      "6662           2024               1                 3              47   \n",
      "6663           2024               1                 1              28   \n",
      "6664           2024               1                 2              28   \n",
      "...             ...             ...               ...             ...   \n",
      "6766           2024               4                 2              69   \n",
      "6767           2024               4                 1              48   \n",
      "6768           2024               3                 3              27   \n",
      "6769           2024               2                 0               0   \n",
      "6770           2024               4                 4              55   \n",
      "\n",
      "      product_ids  delivery_ratio   created_date_time  \n",
      "6580           58        0.978080 2023-09-25 09:01:13  \n",
      "6661            3        1.000000 2023-12-01 07:58:47  \n",
      "6662          117        0.937200 2023-12-01 10:40:08  \n",
      "6663          168        0.972350 2023-12-04 15:11:31  \n",
      "6664          168        1.024000 2023-12-05 11:25:16  \n",
      "...           ...             ...                 ...  \n",
      "6766           64        2.532877 2024-02-14 10:27:51  \n",
      "6767           58        2.352247 2024-02-14 11:50:46  \n",
      "6768          114        0.969440 2024-02-15 16:18:53  \n",
      "6769           58        3.801600 2024-02-16 11:08:14  \n",
      "6770           58        0.409890 2024-02-16 11:40:52  \n",
      "\n",
      "[100 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "train_mask = df[\"time_first_delivery\"] < pd.Timestamp(\"2024-01-01\")\n",
    "\n",
    "X_train, y_train = x[train_mask], y[train_mask]\n",
    "X_test,  y_test  = x[~train_mask], y[~train_mask]\n",
    "\n",
    "# Behold ID-informasjonen også\n",
    "test = df.loc[~train_mask].copy()\n",
    "\n",
    "print(X_test.head(100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a50a686c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: float() argument must be a string or a real number, not 'list'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_30508\\3968412849.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmin_samples_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0msubsample\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.8\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\strom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1469\u001b[0m                 skip_parameter_validation=(\n\u001b[0;32m   1470\u001b[0m                     \u001b[0mprefer_skip_nested_validation\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mglobal_skip_validation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1471\u001b[0m                 \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1472\u001b[0m             \u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1473\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\strom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[0;32m    655\u001b[0m         \u001b[1;31m# Check input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    656\u001b[0m         \u001b[1;31m# Since check_array converts both X and y to the same dtype, but the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    657\u001b[0m         \u001b[1;31m# trees use different types for X and y, checking them separately.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 659\u001b[1;33m         X, y = self._validate_data(\n\u001b[0m\u001b[0;32m    660\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"csc\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"coo\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    661\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    662\u001b[0m         \u001b[0msample_weight_is_none\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\strom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    646\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;34m\"estimator\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mcheck_y_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    647\u001b[0m                     \u001b[0mcheck_y_params\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mdefault_check_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    648\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"y\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    649\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 650\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    651\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\strom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1297\u001b[0m         raise ValueError(\n\u001b[0;32m   1298\u001b[0m             \u001b[1;33mf\"\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mestimator_name\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m requires y to be passed, but the target y is None\u001b[0m\u001b[1;33m\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1301\u001b[1;33m     X = check_array(\n\u001b[0m\u001b[0;32m   1302\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1303\u001b[0m         \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m         \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\strom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m   1009\u001b[0m                         \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1010\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1011\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1012\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_asarray_with_order\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mxp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1013\u001b[1;33m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1014\u001b[0m                 raise ValueError(\n\u001b[0;32m   1015\u001b[0m                     \u001b[1;34m\"Complex data not supported\\n{}\\n\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1016\u001b[0m                 \u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcomplex_warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\strom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(array, dtype, order, copy, xp, device)\u001b[0m\n\u001b[0;32m    741\u001b[0m         \u001b[1;31m# Use NumPy API to support order\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    744\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 745\u001b[1;33m             \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    746\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    747\u001b[0m         \u001b[1;31m# At this point array is a NumPy ndarray. We convert it to an array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m         \u001b[1;31m# container that is consistent with the input's namespace.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\strom\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, dtype, copy)\u001b[0m\n\u001b[0;32m   2149\u001b[0m     def __array__(\n\u001b[0;32m   2150\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnpt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDTypeLike\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool_t\u001b[0m \u001b[1;33m|\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2151\u001b[0m     \u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2152\u001b[0m         \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2153\u001b[1;33m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2154\u001b[0m         if (\n\u001b[0;32m   2155\u001b[0m             \u001b[0mastype_is_view\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2156\u001b[0m             \u001b[1;32mand\u001b[0m \u001b[0musing_copy_on_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "model = GradientBoostingRegressor(\n",
    "    loss = 'quantile',\n",
    "    alpha = 0.2,\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.1,\n",
    "    max_depth=5,\n",
    "    random_state=42,\n",
    "    min_samples_leaf=10,\n",
    "    subsample=0.8,\n",
    ")  \n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "print(f\"RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fba0425",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' from kaggle_metric import score, ParticipantVisibleError\\n\\n\\nreceivals[\"date_arrival\"] = pd.to_datetime(receivals[\"date_arrival\"], errors=\"coerce\", utc=True).dt.tz_localize(None)\\n\\n\\nstart = pd.Timestamp(\"2024-01-01\")\\nend   = pd.Timestamp(\"2024-05-31 23:59:59\")\\nsolution = (receivals.loc[(receivals[\"date_arrival\"] >= start) & (receivals[\"date_arrival\"] <= end)]\\n            .groupby(\"rm_id\", as_index=False)\\n            .agg(weight=(\"net_weight\", \"sum\"))\\n           ).rename(columns={\"rm_id\": \"ID\"})\\n\\n\\nrm_col = \"rm_id_raw\" if \"rm_id_raw\" in test.columns else \"rm_id\"\\n\\npreds = pd.DataFrame({\\n    \"ID\": test[rm_col].values,\\n    \"predicted_weight\": np.clip(y_pred, 0, None)  \\n})\\n\\nsubmission = preds.groupby(\"ID\", as_index=False).agg(predicted_weight=(\"predicted_weight\", \"sum\"))\\n\\n\\nsubmission = solution[[\"ID\"]].merge(submission, on=\"ID\", how=\"left\")\\nsubmission[\"predicted_weight\"] = submission[\"predicted_weight\"].fillna(0.0)\\n\\n\\ntry:\\n    final_score = score(solution=solution, submission=submission, row_id_column_name=\"ID\")\\n    print(\"Quantile loss (q=0.2) – backtest jan–mai 2024:\", final_score)\\nexcept ParticipantVisibleError as e:\\n    print(\"Scoring feilet:\", e)\\n    \\n\\nprint(submission.head())\\nprint(solution.head()) '"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" from kaggle_metric import score, ParticipantVisibleError\n",
    "\n",
    "\n",
    "receivals[\"date_arrival\"] = pd.to_datetime(receivals[\"date_arrival\"], errors=\"coerce\", utc=True).dt.tz_localize(None)\n",
    "\n",
    "\n",
    "start = pd.Timestamp(\"2024-01-01\")\n",
    "end   = pd.Timestamp(\"2024-05-31 23:59:59\")\n",
    "solution = (receivals.loc[(receivals[\"date_arrival\"] >= start) & (receivals[\"date_arrival\"] <= end)]\n",
    "            .groupby(\"rm_id\", as_index=False)\n",
    "            .agg(weight=(\"net_weight\", \"sum\"))\n",
    "           ).rename(columns={\"rm_id\": \"ID\"})\n",
    "\n",
    "\n",
    "rm_col = \"rm_id_raw\" if \"rm_id_raw\" in test.columns else \"rm_id\"\n",
    "\n",
    "preds = pd.DataFrame({\n",
    "    \"ID\": test[rm_col].values,\n",
    "    \"predicted_weight\": np.clip(y_pred, 0, None)  \n",
    "})\n",
    "\n",
    "submission = preds.groupby(\"ID\", as_index=False).agg(predicted_weight=(\"predicted_weight\", \"sum\"))\n",
    "\n",
    "\n",
    "submission = solution[[\"ID\"]].merge(submission, on=\"ID\", how=\"left\")\n",
    "submission[\"predicted_weight\"] = submission[\"predicted_weight\"].fillna(0.0)\n",
    "\n",
    "\n",
    "try:\n",
    "    final_score = score(solution=solution, submission=submission, row_id_column_name=\"ID\")\n",
    "    print(\"Quantile loss (q=0.2) – backtest jan–mai 2024:\", final_score)\n",
    "except ParticipantVisibleError as e:\n",
    "    print(\"Scoring feilet:\", e)\n",
    "    \n",
    "\n",
    "print(submission.head())\n",
    "print(solution.head()) \"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
